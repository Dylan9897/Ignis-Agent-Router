"""
æµ‹è¯•TTSåŠŸèƒ½æ˜¯å¦æ­£å¸¸ - æ”¯æŒå¤šç§éŸ³è‰²
"""
import dashscope
from dashscope.audio.tts import SpeechSynthesizer
from config import DASHSCOPE_API_KEY, SAMPLE_RATE, MODEL_TTS
import pyaudio
import time

# è®¾ç½®API KEY
dashscope.api_key = DASHSCOPE_API_KEY

# é˜¿é‡Œäº‘TTSå®˜æ–¹å¯ç”¨éŸ³è‰²ï¼ˆSambertå¤šæƒ…æ„Ÿï¼‰
VOICE_OPTIONS = {
    "1": ("sambert-zhichu-v1", "çŸ¥è¶£ (æ¸©æŸ”è‡ªç„¶å¥³å£°) â­é»˜è®¤"),
    "2": ("sambert-zhigui-v1", "çŸ¥æŸœ (å®¢æœå¥³å£°)"),
    "3": ("sambert-zhimao-v1", "çŸ¥çŒ« (å¨‡ä¿å¯çˆ±å¥³å£°) ğŸ’•"),
    "4": ("sambert-zhiting-v1", "çŸ¥å©· (ç”µå°å¥³å£°ï¼Œä¼˜é›…çŸ¥æ€§)"),
    "5": ("sambert-zhiyue-v1", "çŸ¥æ‚¦ (æ¸©æŸ”å¥³å£°)"),
    "6": ("sambert-zhiwei-v1", "çŸ¥å¾® (èè‰å¥³å£°ï¼Œé˜…è¯»äº§å“ç®€ä»‹)"),
}

def test_tts(text, voice_model=None):
    """æµ‹è¯•TTSåˆæˆå’Œæ’­æ”¾"""
    # å¦‚æœæ²¡æœ‰æŒ‡å®šéŸ³è‰²ï¼Œä½¿ç”¨é»˜è®¤çš„
    if voice_model is None:
        voice_model = MODEL_TTS
    
    print(f"\n[æµ‹è¯•] å‡†å¤‡åˆæˆæ–‡æœ¬: {text}")
    print(f"[æµ‹è¯•] ä½¿ç”¨éŸ³è‰²æ¨¡å‹: {voice_model}")
    
    try:
        # 1. æµ‹è¯•TTSåˆæˆ
        print("[æµ‹è¯•] æ­£åœ¨è°ƒç”¨TTS...")
        
        result = SpeechSynthesizer.call(
            model=voice_model,
            text=text,
            sample_rate=SAMPLE_RATE
        )
        
        # æ‰“å°å®Œæ•´çš„ç»“æœä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"[è°ƒè¯•] TTSè¿”å›çŠ¶æ€ç : {result.get_response().status_code if result.get_response() else 'N/A'}")
        
        # 2. æ£€æŸ¥éŸ³é¢‘æ•°æ®
        audio_data = result.get_audio_data()
        if audio_data:
            print(f"[æµ‹è¯•] âœ… TTSåˆæˆæˆåŠŸï¼éŸ³é¢‘å¤§å°: {len(audio_data)} å­—èŠ‚")
            
            # 3. æµ‹è¯•æ’­æ”¾
            print("[æµ‹è¯•] æ­£åœ¨æ’­æ”¾...")
            p = pyaudio.PyAudio()
            stream = p.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=SAMPLE_RATE,
                output=True
            )
            
            # åˆ†å—æ’­æ”¾
            chunk_size = 3200
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                stream.write(chunk)
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            print("[æµ‹è¯•] âœ… æ’­æ”¾å®Œæˆï¼")
            return True
        else:
            print("[æµ‹è¯•] âŒ TTSæœªè¿”å›éŸ³é¢‘æ•°æ®")
            print("[æç¤º] å¯èƒ½åŸå› ï¼š")
            print(f"  1. è¯¥éŸ³è‰²æ¨¡å‹ '{voice_model}' å¯èƒ½ä¸å¯ç”¨")
            print(f"  2. API KEYå¯èƒ½æ²¡æœ‰è¯¥éŸ³è‰²çš„ä½¿ç”¨æƒé™")
            print(f"  3. ç½‘ç»œè¿æ¥é—®é¢˜æˆ–TTSæœåŠ¡é™æµ")
            return False
            
    except Exception as e:
        print(f"[æµ‹è¯•] âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ™ï¸  TTS éŸ³è‰²æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥API KEY
    if "sk-" not in DASHSCOPE_API_KEY:
        print("âŒ é”™è¯¯: è¯·åœ¨ config.py ä¸­é…ç½®æ­£ç¡®çš„ DASHSCOPE_API_KEY")
        exit(1)
    
    print(f"âœ… API KEY å·²é…ç½®")
    print(f"âœ… é»˜è®¤é‡‡æ ·ç‡: {SAMPLE_RATE}")
    
    # æ˜¾ç¤ºå¯ç”¨éŸ³è‰²
    print("\n" + "=" * 60)
    print("ğŸ“¢ å¯ç”¨éŸ³è‰²åˆ—è¡¨ï¼š")
    print("=" * 60)
    for key, (model, desc) in VOICE_OPTIONS.items():
        print(f"  {key:2s}. {desc}")
    print("\n  0. é€€å‡º")
    
    # æµ‹è¯•æ–‡æœ¬é€‰é¡¹
    test_texts = [
        "ä½ å¥½ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚",
        "å¥½çš„ï¼Œæˆ‘å·²ç»ç»™å†¬ç“œå‘é€äº†æ™šä¸Šå¼€ä¼šã€‚",
        "å·²ç»ä¸ºæ‚¨æ‰¾åˆ°å¹¶æ‰“å¼€äº†æµ‹è¯•æŠ¥å‘Šç›¸å…³çš„æ–‡ä»¶ã€‚",
        "å¥½çš„ï¼ŒPPTå·²ç»å¼€å§‹æ’­æ”¾ï¼Œè¯·æ³¨æ„æŸ¥çœ‹ã€‚",
        "ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œå¿ƒæƒ…ä¹Ÿè·Ÿç€å¥½èµ·æ¥äº†ã€‚"
    ]
    
    while True:
        print("\n" + "=" * 60)
        choice = input("è¯·é€‰æ‹©éŸ³è‰²ç¼–å· (0é€€å‡º): ").strip()
        
        if choice == "0":
            print("\nğŸ‘‹ å†è§ï¼")
            break
        
        if choice not in VOICE_OPTIONS:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            continue
        
        voice_model, voice_desc = VOICE_OPTIONS[choice]
        
        print(f"\nğŸµ å·²é€‰æ‹©: {voice_desc}")
        print(f"ğŸ“ éŸ³è‰²æ¨¡å‹: {voice_model}")
        
        # è®©ç”¨æˆ·é€‰æ‹©æµ‹è¯•æ–‡æœ¬æˆ–è‡ªå®šä¹‰
        print("\nå¯é€‰æµ‹è¯•æ–‡æœ¬ï¼š")
        for i, text in enumerate(test_texts, 1):
            print(f"  {i}. {text}")
        print(f"  {len(test_texts) + 1}. è‡ªå®šä¹‰æ–‡æœ¬")
        
        text_choice = input(f"\nè¯·é€‰æ‹©æ–‡æœ¬ (1-{len(test_texts) + 1}): ").strip()
        
        if text_choice.isdigit():
            text_idx = int(text_choice)
            if 1 <= text_idx <= len(test_texts):
                test_text = test_texts[text_idx - 1]
            elif text_idx == len(test_texts) + 1:
                test_text = input("è¯·è¾“å…¥è‡ªå®šä¹‰æ–‡æœ¬: ").strip()
                if not test_text:
                    test_text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"
            else:
                print("âŒ æ— æ•ˆçš„é€‰æ‹©")
                continue
        else:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©")
            continue
        
        # æ‰§è¡Œæµ‹è¯•
        test_tts(test_text, voice_model)
        
        time.sleep(0.5)
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)

