# encoding : utf-8 -*-                            
# @author  : å†¬ç“œ                              
# @mail    : dylan_han@126.com    
# @Time    : 2026/2/2 15:19
import sys
import json
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# === 1. åŸºç¡€é…ç½® ===
API_KEY = "sk-cdaa3135a6294568958aa335cad6b7fe"
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"


class GenerateLLMResponse:
    def __init__(self):
        # åˆå§‹åŒ–å¤§æ¨¡å‹ï¼Œå¼€å¯ streaming=True
        # StreamingStdOutCallbackHandler ä¼šè®© Token å®æ—¶æ‰“å°åœ¨æ§åˆ¶å°
        self.llm = ChatOpenAI(
            openai_api_key=API_KEY,
            openai_api_base=BASE_URL,
            model_name="qwen-plus",
            streaming=True,
            callbacks=[StreamingStdOutCallbackHandler()],
            temperature=0.8
        )

        self.system_prompt = SystemMessage(content=(
            "ä½ çš„åå­—å«â€˜è•‰ç»¿è›™â€™ï¼Œèº«ä»½æ˜¯ç”¨æˆ·çš„ä¸“å±â€˜AI æ•°å­—äººç§˜ä¹¦â€™ã€‚"
            "ä½ çš„æ ¸å¿ƒå£å¤´ç¦…æ˜¯â€˜ä¸è¦ç„¦è™‘å“‡â€™ï¼Œæ—¨åœ¨åŒ–è§£åŠå…¬å‹åŠ›ã€‚"
            "èŒè´£èŒƒå›´ï¼šä½ ç²¾é€š Python è‡ªåŠ¨åŒ–ï¼Œèƒ½å¸®ç”¨æˆ·æ§åˆ¶ PPTï¼ˆæ’­æ”¾ã€ç¿»é¡µï¼‰ã€ä»£å‘å¾®ä¿¡æ¶ˆæ¯ã€æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶ã€‚"
            "æ€§æ ¼ç”»åƒï¼šä¸“ä¸šã€å¹½é»˜ã€æ²»æ„ˆç³»ã€‚å›å¤è¦ç®€ç»ƒé«˜æ•ˆï¼Œå¸¦æœ‰æ•°å­—äººçš„äº²å’ŒåŠ›ã€‚"
        ))
        self.chat_history = [self.system_prompt]

    async def ask(self, query: str):
        """æµå¼æé—®æ–¹æ³•"""
        print(f"\nğŸ¸ è•‰ç»¿è›™: ", end="")
        self.chat_history.append(HumanMessage(content=query))

        # è°ƒç”¨ astream è¿›è¡Œå¼‚æ­¥æµå¼è·å–
        full_response = ""
        try:
            # åœ¨ LangChain ä¸­ï¼Œç›´æ¥è°ƒç”¨ stream æ–¹æ³•
            for chunk in self.llm.stream(self.chat_history):
                # chunk æ˜¯ BaseMessageChunk å¯¹è±¡
                content = chunk.content
                full_response += content
                # è¿™é‡Œä¸éœ€è¦æ‰‹åŠ¨ printï¼Œå› ä¸º callbacks å·²ç»å¤„ç†äº† stdout

            # å°†å›å¤å­˜å…¥å†å²ï¼Œç»´æŒä¸Šä¸‹æ–‡
            self.chat_history.append(full_response)
        except Exception as e:
            print(f"\nâŒ [å¼‚å¸¸]: {e}")

    # ============ è¿™æ˜¯æ–°å¢çš„å‡½æ•° ============
    def invoke_command(self, instruction: str):
        """[éæµå¼] ç”¨äºæ‰§è¡Œå…·ä½“æŒ‡ä»¤ï¼Œä¸€æ¬¡æ€§è¿”å›ç»“æœ"""
        print(f"\nğŸŒ€ è•‰ç»¿è›™æ­£åœ¨å¤„ç†ä»»åŠ¡æ¸…å•...")

        # æŒ‡ä»¤é€šå¸¸ä¸éœ€è¦å¤ªé•¿çš„ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æ¶ˆæ¯åˆ—è¡¨
        messages = [
            self.system_prompt,
            HumanMessage(content=f"è¯·æ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼š{instruction}")
        ]

        try:
            # ä½¿ç”¨ invoke ä»£æ›¿ stream
            response = self.llm.invoke(messages)
            # è¿™é‡Œçš„ response æ˜¯ä¸€ä¸ªå®Œæ•´çš„ AIMessage å¯¹è±¡
            return response.content
        except Exception as e:
            return f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {e}"

    def extract_wechat_demo(self, user_input: str):
        """
        ä¸“é—¨ç”¨äºä»è‡ªç„¶è¯­è¨€ä¸­æå–å¾®ä¿¡å‘é€æ‰€éœ€çš„å…ƒæ•°æ®
        """
        extraction_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæŒ‡ä»¤è§£æå™¨ã€‚è¯·ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å¾®ä¿¡è”ç³»äººå§“åå’Œæ¶ˆæ¯å†…å®¹ã€‚"
            "å¿…é¡»ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œä¾‹å¦‚ï¼š{\"contact_name\": \"å¼ ä¸‰\", \"message_content\": \"ä½ å¥½\"}ã€‚"
        )

        messages = [
            SystemMessage(content=extraction_prompt),
            HumanMessage(content=user_input)
        ]

        # ä½¿ç”¨éæµå¼è°ƒç”¨è·å–ç»“æœ
        response = self.llm.invoke(messages)

        try:
            # è§£æ JSON ç»“æœ
            data = json.loads(response.content)
            return data["contact_name"], data["message_content"]
        except Exception as e:
            print(f"è§£ææŒ‡ä»¤å¤±è´¥: {e}")
            return None, None

# === 3. è¿è¡Œæµ‹è¯• ===
if __name__ == "__main__":
    import asyncio

    async def main():
        bot = GenerateLLMResponse()
        print("ğŸŸ¢ è•‰ç»¿è›™å·²ä¸Šçº¿ï¼(è¾“å…¥ 'exit' é€€å‡º)")

        while True:
            user_input = input("\nğŸ‘¤ ä½ : ")
            if user_input.lower() in ['exit', 'quit', 'é€€å‡º']:
                break

            await bot.ask(user_input)
            print()  # æ¢è¡Œ

    asyncio.run(main())